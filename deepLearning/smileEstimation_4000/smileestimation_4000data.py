# -*- coding: utf-8 -*-
"""smileEstimation_4000data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j0Ycms7Q9RMrYR64kvfWEEXisngI56Fy
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential, Model
from keras.layers import Input, Dense, Dropout, Activation, Flatten,MaxPooling2D,Conv2D
from keras import optimizers
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.optimizers import Adam

classes = ['neutral', 'happy']
nb_classes = len(classes)
batch_size_for_data_generator = 20

base_dir = '/content/drive/MyDrive/JPHACKS21/SmileEstimation_Genki/GENKI-4K/sprit_data'

train_dir = base_dir+'/train'
valid_dir = base_dir+'/validation'

# 要調整
img_rows, img_cols = 180, 180

train_datagen = ImageDataGenerator(rescale=1.0 / 255,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True)
train_generator = train_datagen.flow_from_directory(directory=train_dir,
                                                    target_size=(img_rows, img_cols),
                                                    color_mode='rgb',
                                                    classes=classes,
                                                    class_mode='categorical',
                                                    batch_size=32,
                                                    shuffle=True)

test_datagen = ImageDataGenerator(rescale=1.0 / 255)
valid_generator = test_datagen.flow_from_directory(directory=valid_dir,
                                                   target_size=(img_rows, img_cols),
                                                   color_mode='rgb',
                                                   classes=classes,
                                                   class_mode='categorical',
                                                   batch_size=32,
                                                   shuffle=True)

model=Sequential()
# 畳み込み層
model.add(Conv2D(32,(3,3),activation='relu',input_shape=(img_rows, img_cols, 3)))
model.add(MaxPooling2D((2,2)))

model.add(Conv2D(64,(3,3),activation='relu'))
model.add(MaxPooling2D((2,2)))

model.add(Conv2D(128,(3,3),activation='relu'))
model.add(MaxPooling2D((2,2)))

model.add(Conv2D(128,(3,3),activation='relu'))
model.add(MaxPooling2D((2,2)))

# 全結合層
model.add(Flatten())
model.add(Dense(512,activation='relu'))
# 出力層
model.add(Dense(nb_classes,activation='softmax'))
          
model.summary()

opt = Adam(lr=0.001, decay=1e-6)
model.compile(loss='categorical_crossentropy',
              optimizer= opt, 
              metrics=['acc'])

history = model.fit(train_generator,
                    steps_per_epoch=99,
                    epochs=90,
                    validation_data=valid_generator,
                    validation_steps=25,
                    verbose=1)

hdf5_file = os.path.join(base_dir, 'smileEstimation_4000data.hdf5')
model.save(hdf5_file)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()